# ðŸš€ Job Market Insight: MÃ¡laga & Granada (IT Edition)

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)
![Raspberry Pi](https://img.shields.io/badge/-Raspberry_Pi-C51A4A?style=for-the-badge&logo=Raspberry-Pi&logoColor=white)
![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white)
![Charts](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)

Este proyecto automatiza la extracciÃ³n, limpieza y anÃ¡lisis de ofertas de empleo en el sector tecnolÃ³gico para **MÃ¡laga** y **Granada**, analizando tanto el mercado local como el nacional en remoto.

El objetivo principal es identificar el **stack tecnolÃ³gico real** que las empresas demandan para perfiles **Junior (Entry Level)** en 2026.

---

## ðŸ¤– AutomatizaciÃ³n con Raspberry Pi (Edge Scraping)

Para garantizar una base de datos robusta sin intervenciÃ³n manual, el sistema se ha desplegado en una **Raspberry Pi Zero 2 W**, con procesos optimizados para hardware limitado:

* **ExtracciÃ³n Diaria (`Scrapping.py`):** EjecuciÃ³n automatizada vÃ­a `cron` cada madrugada. Captura ofertas de las Ãºltimas 24h y las organiza en carpetas diarias dentro de `scraps/`.
* **ConsolidaciÃ³n Mensual (`Join.py`):** El dÃ­a 1 de cada mes, el sistema fusiona los CSVs del mes anterior, realiza una deduplicaciÃ³n profunda y genera un **Dataset Maestro**, eliminando los archivos temporales para optimizar el almacenamiento.

---

## ðŸ“Š Insights del Mercado (Febrero 2026)

### ðŸ” Top 5 TecnologÃ­as Globales (All Levels)
| TecnologÃ­a | Menciones | Rol en el Mercado |
| :--- | :--- | :--- |
| **Python** | 547 | Dominio absoluto en Data, Scripting y Backend |
| **SQL** | 390 | Base de datos: el requisito transversal por excelencia |
| **CI/CD** | 299 | AutomatizaciÃ³n de despliegue en casi el 55% de las ofertas |
| **AWS** | 285 | El proveedor Cloud preferido por las empresas |
| **Docker** | 259 | EstÃ¡ndar de facto para contenedorizaciÃ³n |

### ðŸ‘¶ Perfil Junior / Entry Level
| TecnologÃ­a | Menciones | ObservaciÃ³n |
| :--- | :--- | :--- |
| **Python** | 121 | La puerta de entrada mÃ¡s comÃºn al sector |
| **Kubernetes** | 71 | Tendencia crÃ­tica: ya se exige orquestaciÃ³n a Juniors |
| **Docker** | 67 | Conocimiento bÃ¡sico de contenedores indispensable |
| **CI/CD** | 64 | DevOps culture desde el primer dÃ­a |
| **Go** | 63 | Sorprendente auge de Go para nuevos perfiles en sistemas/backend |

* **AnÃ¡lisis de Tendencia:** Se observa una "DevOps-izaciÃ³n" del perfil Junior. Ya no basta con saber programar (Python); el mercado exige que el desarrollador sepa dÃ³nde y cÃ³mo corre su cÃ³digo (**Kubernetes**, **Docker**, **CI/CD**).
* **MÃ¡laga vs Granada:** MÃ¡laga mantiene el liderazgo en volumen de ofertas Cloud, mientras que Granada muestra una especializaciÃ³n notable en arquitecturas eficientes (Go).

---

## ðŸ› ï¸ TecnologÃ­as y LibrerÃ­as
* **Scraping:** `python-jobspy` (LinkedIn API Wrapper)
* **AutomatizaciÃ³n:** `Crontab` (Linux) & `Logging`
* **AnÃ¡lisis de Datos:** `Pandas`, `NumPy`, `Scikit-Learn`
* **Procesamiento de Texto:** `Regex` & `NLTK` (Stopwords)
* **VisualizaciÃ³n:** `Matplotlib` & `Seaborn`

---

## ðŸ“ Estructura del Proyecto
```text
â”œâ”€â”€ scraps/                 # CSVs crudos organizados por fechas (DD-MM-YYYY o MM-YYYY)
â”œâ”€â”€ logs/                   # Registros de ejecuciÃ³n de tareas programadas
â”œâ”€â”€ Scrapping.py            # Script de extracciÃ³n diaria (ProducciÃ³n)
â”œâ”€â”€ Join.py                 # Script de consolidaciÃ³n mensual (ProducciÃ³n)
â”œâ”€â”€ Tratamiento.ipynb       # Notebook de limpieza y procesamiento
â””â”€â”€ README.md               # DocumentaciÃ³n
```
## âš™ï¸ AutomatizaciÃ³n (Crontab Configuration)

Para garantizar la autonomÃ­a del proyecto en la **Raspberry Pi Zero 2 W**, se han programado dos tareas principales. Estas incluyen flags de optimizaciÃ³n de memoria para evitar colapsos en los 512MB de RAM del dispositivo.

### 1. ExtracciÃ³n Diaria (Scraping)
Se ejecuta todas las madrugadas para capturar las nuevas ofertas publicadas en las Ãºltimas 24 horas.

```bash
00 05 * * * cd /home/pacc/Desktop/scrapping && MALLOC_TRIM_THRESHOLD_=65536 PYTHONMALLOC=malloc ./env/bin/python3 -O Scrapping.py >> logs/cron_diario_$(date +\%d-\%m-\%Y).log 2>&1
```

### 2. ConsolidaciÃ³n mensual de datasets ejecutada cada dÃ­a 1 a la 01:00 AM, con gestiÃ³n optimizada de memoria RAM para hardware limitado y registro de logs fechados(Join)
```bash
00 01 1 * * cd /home/pacc/Desktop/scrapping && MALLOC_TRIM_THRESHOLD_=65536 PYTHONMALLOC=malloc ./env/bin/python3 -O Join.py >> logs/cron_mensual_$(date +\%m-\%Y).log 2>&1
```
